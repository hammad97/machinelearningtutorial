{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport time\nimport os\nimport cv2\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\ndef read_kaggle_data():\n    imageList = []\n    angList = []\n    with open(\"/kaggle/input/car-steering-angle-prediction/driving_dataset/angles.txt\") as ang:\n        for x in ang:\n            angList.append(float(x.split()[1]))\n            f = x.split()[0]\n            image = cv2.imread('/kaggle/input/car-steering-angle-prediction/driving_dataset/' + f)\n            image_u = cv2.resize(image, (200,66), interpolation = cv2.INTER_AREA) #in given paper\n            imageList.append(torch.from_numpy(image_u.transpose()).float())\n    return list(zip(imageList,angList))\n\n\ndataset = read_kaggle_data()\n\ntrain_x = dataset[0: (len(dataset) - 13000)]\nval_x = dataset[(len(dataset) - 13000) : (len(dataset) - 10000)]\ntest_x = dataset[(len(dataset) - 10000) : (len(dataset))]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-14T20:28:11.874600Z","iopub.execute_input":"2022-01-14T20:28:11.875350Z","iopub.status.idle":"2022-01-14T20:35:08.821601Z","shell.execute_reply.started":"2022-01-14T20:28:11.875304Z","shell.execute_reply":"2022-01-14T20:35:08.819783Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass ConvNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.normal = nn.LayerNorm([200,66])\n        self.conv1 = nn.Conv2d(3,  24, stride=2, kernel_size=5 ,padding=0) \n        self.conv2 = nn.Conv2d(24, 36, stride=2, kernel_size=5, padding=0)\n        self.conv3 = nn.Conv2d(36, 48, stride=2, kernel_size=5, padding=0)\n        self.conv4 = nn.Conv2d(48, 64, stride=1, kernel_size=3, padding=0)\n        self.conv5 = nn.Conv2d(64, 64, stride=1, kernel_size=3, padding=0)\n        self.lin1 = nn.Linear(1152, 100)\n        self.lin2 = nn.Linear(100, 50)\n        self.lin3 = nn.Linear(50, 10)\n        self.lin4 = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        x = self.normal(x)\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        \n        x = x.view(x.shape[0], -1)\n        \n        x = F.relu(self.lin1(x))\n        x = F.relu(self.lin2(x))\n        x = F.relu(self.lin3(x))\n        x = self.lin4(x)\n        return x\n\n\nnet = ConvNet()\nn_iter = 25\nb_size = 250\nmu = 1e-4\ntr_loss_list, vl_loss_list = [], []\noptm = torch.optim.Adam(net.parameters(), lr = mu)\nrms = torch.nn.MSELoss(reduction = 'sum')\n\np_start = time.time()\n\nfor epoch in range(n_iter):\n    lo = 0\n    s_time = time.time()\n    d_load = torch.utils.data.DataLoader(train_x, batch_size = b_size, shuffle = True)\n    outp = \"epoch \" + str(epoch) + \" | \"\n    for i, val in enumerate(d_load):\n        optm.zero_grad()\n        y_val = torch.reshape(val[1], (val[1].shape[0], 1)).type(torch.float32)\n        loss = rms(net(val[0]), y_val)\n        lo = lo + loss.item()\n        loss.backward()\n        optm.step()\n    outp = outp + str(\"train RMSE : \" + str(np.sqrt(lo / len(train_x)))) + \" | \"\n    tr_loss_list.append(np.sqrt(lo / len(train_x)))\n\n    v_load = torch.utils.data.DataLoader(val_x, batch_size = b_size, shuffle = True)\n    lo_tmp = 0\n\n    for i, val in enumerate(v_load):\n        y_val = torch.reshape(val[1], (val[1].shape[0], 1)).type(torch.float32)\n        loss = rms(net(val[0]), y_val)\n        lo_tmp = lo_tmp + loss.item()\n    outp = outp + \"val RMSE : \" + str(np.sqrt(lo_tmp / len(val_x))) + \" | \"\n\n    e_time = time.time()\n    outp = outp + 'Epoch time(s): ' + str(e_time - s_time) + \" | \"\n    vl_loss_list.append(np.sqrt(lo_tmp / len(val_x)))\n\n    print(outp)\n    \nt_load = torch.utils.data.DataLoader(test_x, batch_size = b_size, shuffle = True)\nlo_test = 0\n\nfor i, tval in enumerate(t_load):\n    y_val = torch.reshape(tval[1], (tval[1].shape[0], 1)).type(torch.float32)\n    loss = rms(net(tval[0]), y_val)\n    lo_test = lo_test + loss.item()\n\nprint(\"Testing RMSE : \", vl_loss_list)\n\np_end = time.time()\nprint('Total execution time: ', (p_end - p_start))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:08:50.281201Z","iopub.execute_input":"2022-01-14T21:08:50.282055Z","iopub.status.idle":"2022-01-14T22:01:05.385332Z","shell.execute_reply.started":"2022-01-14T21:08:50.282011Z","shell.execute_reply":"2022-01-14T22:01:05.384520Z"},"trusted":true},"execution_count":10,"outputs":[]}]}